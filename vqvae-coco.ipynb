{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from latent_diffusion.models import VQVAE\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/coco17.yaml\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQVAE(cfg).to(cfg[\"trainer\"][\"device\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = pt.load(\"model_checkpoint_r56.pth\", weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQVAE(\n",
       "  (encoder): Encoder(\n",
       "    (in_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (layers): ModuleDict(\n",
       "      (DownBlock_0): ModuleDict(\n",
       "        (resblock_0): ModuleDict(\n",
       "          (resblock_0_0): ResBlock(\n",
       "            (tr_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (resblock_0_1): ResBlock(\n",
       "            (tr_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downblock): ResBlock(\n",
       "          (tr_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn_tr): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (DownBlock_1): ModuleDict(\n",
       "        (resblock_1): ModuleDict(\n",
       "          (resblock_1_0): ResBlock(\n",
       "            (tr_conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (resblock_1_1): ResBlock(\n",
       "            (tr_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downblock): ResBlock(\n",
       "          (tr_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn_tr): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (DownBlock_2): ModuleDict(\n",
       "        (resblock_2): ModuleDict(\n",
       "          (resblock_2_0): ResBlock(\n",
       "            (tr_conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (resblock_2_1): ResBlock(\n",
       "            (tr_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attnblock_2): AttnBlock(\n",
       "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (MidBlock): ModuleDict(\n",
       "        (mid_resblock1): ResBlock(\n",
       "          (tr_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn_tr): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (mid_attn): AttnBlock(\n",
       "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (mid_resblock2): ResBlock(\n",
       "          (tr_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn_tr): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (OutNorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (OutConv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (vq): Quantizer()\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (mid): Module(\n",
       "      (block_1): ResBlock(\n",
       "        (tr_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_tr): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "        (proj_out): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResBlock(\n",
       "        (tr_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn_tr): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (tr_conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1-2): 2 x ResBlock(\n",
       "            (tr_conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResBlock(\n",
       "            (tr_conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1-2): 2 x ResBlock(\n",
       "            (tr_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): UpsamplingNearest2d(scale_factor=2.0, mode='nearest')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-2): 3 x ResBlock(\n",
       "            (tr_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn_tr): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (layers): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList(\n",
       "          (0-2): 3 x AttnBlock(\n",
       "            (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (norm): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (proj_out): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsample): Upsample(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): UpsamplingNearest2d(scale_factor=2.0, mode='nearest')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_out): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (percept_loss): PerceptualLoss(\n",
       "    (vgg): VGG(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (13): ReLU(inplace=True)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (15): ReLU(inplace=True)\n",
       "        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (17): ReLU(inplace=True)\n",
       "        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (20): ReLU(inplace=True)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (22): ReLU(inplace=True)\n",
       "        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (24): ReLU(inplace=True)\n",
       "        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (26): ReLU(inplace=True)\n",
       "        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (29): ReLU(inplace=True)\n",
       "        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (31): ReLU(inplace=True)\n",
       "        (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (33): ReLU(inplace=True)\n",
       "        (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (35): ReLU(inplace=True)\n",
       "        (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "      (classifier): Sequential(\n",
       "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "        (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Dropout(p=0.5, inplace=False)\n",
       "        (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (13): ReLU(inplace=True)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (15): ReLU(inplace=True)\n",
       "        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (17): ReLU(inplace=True)\n",
       "        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (20): ReLU(inplace=True)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (22): ReLU(inplace=True)\n",
       "        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (24): ReLU(inplace=True)\n",
       "        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (26): ReLU(inplace=True)\n",
       "        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook = model.vq.codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image(\"apple.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.unsqueeze(0).to(cfg[\"trainer\"][\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_, cd, cl, cdl, rl, pl, _ = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = x_.squeeze(0).detach().permute((1,2,0)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0497, -0.0642, -0.0531,  ..., -0.0743, -0.0203, -0.0172],\n",
       "          [ 0.0212,  0.0569,  0.0775,  ...,  0.3494,  0.2873,  0.2600],\n",
       "          [ 0.2658,  0.1765,  0.0572,  ..., -0.1873, -0.0275,  0.0342],\n",
       "          ...,\n",
       "          [-0.0351, -0.0324, -0.0263,  ..., -0.0207, -0.0323, -0.0095],\n",
       "          [-0.0496, -0.0303, -0.0370,  ..., -0.0366, -0.0345, -0.0507],\n",
       "          [-0.0867, -0.0664, -0.0681,  ..., -0.0315, -0.0841, -0.0805]],\n",
       "\n",
       "         [[-0.0119, -0.0148, -0.0202,  ..., -0.0798, -0.0081, -0.0116],\n",
       "          [ 0.0193,  0.0560,  0.0724,  ...,  0.3604,  0.2928,  0.2672],\n",
       "          [ 0.2703,  0.1815,  0.0630,  ..., -0.1761, -0.0274,  0.0235],\n",
       "          ...,\n",
       "          [-0.0247,  0.0047, -0.0080,  ..., -0.0157, -0.0178, -0.0160],\n",
       "          [-0.0273, -0.0257, -0.0142,  ..., -0.0166, -0.0188, -0.0080],\n",
       "          [-0.0097, -0.0170, -0.0232,  ..., -0.0421, -0.0287, -0.0344]],\n",
       "\n",
       "         [[-0.0069, -0.0105, -0.0378,  ..., -0.0302, -0.0183, -0.0578],\n",
       "          [-0.0427, -0.0536, -0.0065,  ..., -0.0419, -0.0484, -0.0486],\n",
       "          [-0.0332, -0.0603, -0.0570,  ..., -0.0672, -0.0714, -0.0561],\n",
       "          ...,\n",
       "          [-0.0326, -0.0856, -0.0735,  ..., -0.0343, -0.0121, -0.0384],\n",
       "          [-0.0244, -0.0773, -0.0510,  ..., -0.0407, -0.0905, -0.1109],\n",
       "          [-0.0850, -0.0495, -0.0639,  ..., -0.0658, -0.0560, -0.0328]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2844, -0.3167, -0.2362,  ..., -0.5892, -0.5994, -0.6236],\n",
       "          [-0.6121, -0.5612, -0.4421,  ..., -1.3802, -1.4210, -1.4004],\n",
       "          [-1.3568, -1.3633, -1.2283,  ..., -2.2939, -2.3885, -2.2717],\n",
       "          ...,\n",
       "          [-0.3055, -0.2903, -0.2573,  ..., -0.2066, -0.2219, -0.2219],\n",
       "          [-0.2335, -0.2286, -0.1888,  ..., -0.2045, -0.1682, -0.1926],\n",
       "          [-0.1948, -0.1979, -0.1702,  ..., -0.1782, -0.1935, -0.1879]],\n",
       "\n",
       "         [[-0.1795, -0.2310, -0.1770,  ..., -0.2417, -0.2258, -0.2471],\n",
       "          [-0.2369, -0.2556, -0.2079,  ..., -0.2843, -0.2977, -0.2819],\n",
       "          [-0.2934, -0.3239, -0.2758,  ..., -0.4491, -0.4491, -0.4117],\n",
       "          ...,\n",
       "          [-1.6582, -1.8450, -2.0762,  ..., -1.9116, -1.8919, -1.9943],\n",
       "          [-2.2100, -2.3944, -2.5035,  ..., -1.9725, -1.9526, -1.9362],\n",
       "          [-2.1387, -2.2067, -2.2601,  ..., -1.5194, -1.4403, -1.4857]],\n",
       "\n",
       "         [[-1.2241, -1.2594, -1.2395,  ..., -0.8407, -0.7883, -0.8044],\n",
       "          [-0.7953, -0.7315, -0.7343,  ..., -0.5224, -0.4848, -0.4546],\n",
       "          [-0.4517, -0.4468, -0.4764,  ..., -0.3181, -0.3057, -0.3081],\n",
       "          ...,\n",
       "          [-1.5224, -1.7125, -1.9493,  ..., -1.9125, -1.8798, -2.0470],\n",
       "          [-2.3031, -2.4985, -2.6557,  ..., -2.2130, -2.1958, -2.2139],\n",
       "          [-2.4862, -2.5899, -2.6804,  ..., -1.9073, -1.8012, -1.8852]]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.030678801..1.0756322].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ede64c261a0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10,15))\n",
    "plt.imshow(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 14, 14])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.models import UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mUNet2DConditionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msample_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter_input_sample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mflip_sin_to_cos\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfreq_shift\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdown_block_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CrossAttnDownBlock2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CrossAttnDownBlock2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CrossAttnDownBlock2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DownBlock2D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmid_block_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'UNetMidBlock2DCrossAttn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mup_block_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'UpBlock2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CrossAttnUpBlock2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CrossAttnUpBlock2D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CrossAttnUpBlock2D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0monly_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mblock_out_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlayers_per_block\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdownsample_padding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmid_block_scale_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mact_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'silu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm_num_groups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm_eps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcross_attention_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtransformer_layers_per_block\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreverse_transformer_layers_per_block\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder_hid_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder_hid_dim_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattention_head_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdual_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_linear_projection\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_embed_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maddition_embed_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maddition_time_embed_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_class_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mupcast_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresnet_time_scale_shift\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresnet_skip_time_act\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresnet_out_scale_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtime_embedding_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtime_embedding_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtime_embedding_act_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimestep_post_act\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtime_cond_proj_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconv_in_kernel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mconv_out_kernel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprojection_class_embeddings_input_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattention_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_embeddings_concat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmid_block_only_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcross_attention_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maddition_embed_type_num_heads\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "A conditional 2D UNet model that takes a noisy sample, conditional state, and a timestep and returns a sample\n",
      "shaped output.\n",
      "\n",
      "This model inherits from [`ModelMixin`]. Check the superclass documentation for it's generic methods implemented\n",
      "for all models (such as downloading or saving).\n",
      "\n",
      "Parameters:\n",
      "    sample_size (`int` or `Tuple[int, int]`, *optional*, defaults to `None`):\n",
      "        Height and width of input/output sample.\n",
      "    in_channels (`int`, *optional*, defaults to 4): Number of channels in the input sample.\n",
      "    out_channels (`int`, *optional*, defaults to 4): Number of channels in the output.\n",
      "    center_input_sample (`bool`, *optional*, defaults to `False`): Whether to center the input sample.\n",
      "    flip_sin_to_cos (`bool`, *optional*, defaults to `True`):\n",
      "        Whether to flip the sin to cos in the time embedding.\n",
      "    freq_shift (`int`, *optional*, defaults to 0): The frequency shift to apply to the time embedding.\n",
      "    down_block_types (`Tuple[str]`, *optional*, defaults to `(\"CrossAttnDownBlock2D\", \"CrossAttnDownBlock2D\", \"CrossAttnDownBlock2D\", \"DownBlock2D\")`):\n",
      "        The tuple of downsample blocks to use.\n",
      "    mid_block_type (`str`, *optional*, defaults to `\"UNetMidBlock2DCrossAttn\"`):\n",
      "        Block type for middle of UNet, it can be one of `UNetMidBlock2DCrossAttn`, `UNetMidBlock2D`, or\n",
      "        `UNetMidBlock2DSimpleCrossAttn`. If `None`, the mid block layer is skipped.\n",
      "    up_block_types (`Tuple[str]`, *optional*, defaults to `(\"UpBlock2D\", \"CrossAttnUpBlock2D\", \"CrossAttnUpBlock2D\", \"CrossAttnUpBlock2D\")`):\n",
      "        The tuple of upsample blocks to use.\n",
      "    only_cross_attention(`bool` or `Tuple[bool]`, *optional*, default to `False`):\n",
      "        Whether to include self-attention in the basic transformer blocks, see\n",
      "        [`~models.attention.BasicTransformerBlock`].\n",
      "    block_out_channels (`Tuple[int]`, *optional*, defaults to `(320, 640, 1280, 1280)`):\n",
      "        The tuple of output channels for each block.\n",
      "    layers_per_block (`int`, *optional*, defaults to 2): The number of layers per block.\n",
      "    downsample_padding (`int`, *optional*, defaults to 1): The padding to use for the downsampling convolution.\n",
      "    mid_block_scale_factor (`float`, *optional*, defaults to 1.0): The scale factor to use for the mid block.\n",
      "    dropout (`float`, *optional*, defaults to 0.0): The dropout probability to use.\n",
      "    act_fn (`str`, *optional*, defaults to `\"silu\"`): The activation function to use.\n",
      "    norm_num_groups (`int`, *optional*, defaults to 32): The number of groups to use for the normalization.\n",
      "        If `None`, normalization and activation layers is skipped in post-processing.\n",
      "    norm_eps (`float`, *optional*, defaults to 1e-5): The epsilon to use for the normalization.\n",
      "    cross_attention_dim (`int` or `Tuple[int]`, *optional*, defaults to 1280):\n",
      "        The dimension of the cross attention features.\n",
      "    transformer_layers_per_block (`int`, `Tuple[int]`, or `Tuple[Tuple]` , *optional*, defaults to 1):\n",
      "        The number of transformer blocks of type [`~models.attention.BasicTransformerBlock`]. Only relevant for\n",
      "        [`~models.unets.unet_2d_blocks.CrossAttnDownBlock2D`], [`~models.unets.unet_2d_blocks.CrossAttnUpBlock2D`],\n",
      "        [`~models.unets.unet_2d_blocks.UNetMidBlock2DCrossAttn`].\n",
      "    reverse_transformer_layers_per_block : (`Tuple[Tuple]`, *optional*, defaults to None):\n",
      "        The number of transformer blocks of type [`~models.attention.BasicTransformerBlock`], in the upsampling\n",
      "        blocks of the U-Net. Only relevant if `transformer_layers_per_block` is of type `Tuple[Tuple]` and for\n",
      "        [`~models.unets.unet_2d_blocks.CrossAttnDownBlock2D`], [`~models.unets.unet_2d_blocks.CrossAttnUpBlock2D`],\n",
      "        [`~models.unets.unet_2d_blocks.UNetMidBlock2DCrossAttn`].\n",
      "    encoder_hid_dim (`int`, *optional*, defaults to None):\n",
      "        If `encoder_hid_dim_type` is defined, `encoder_hidden_states` will be projected from `encoder_hid_dim`\n",
      "        dimension to `cross_attention_dim`.\n",
      "    encoder_hid_dim_type (`str`, *optional*, defaults to `None`):\n",
      "        If given, the `encoder_hidden_states` and potentially other embeddings are down-projected to text\n",
      "        embeddings of dimension `cross_attention` according to `encoder_hid_dim_type`.\n",
      "    attention_head_dim (`int`, *optional*, defaults to 8): The dimension of the attention heads.\n",
      "    num_attention_heads (`int`, *optional*):\n",
      "        The number of attention heads. If not defined, defaults to `attention_head_dim`\n",
      "    resnet_time_scale_shift (`str`, *optional*, defaults to `\"default\"`): Time scale shift config\n",
      "        for ResNet blocks (see [`~models.resnet.ResnetBlock2D`]). Choose from `default` or `scale_shift`.\n",
      "    class_embed_type (`str`, *optional*, defaults to `None`):\n",
      "        The type of class embedding to use which is ultimately summed with the time embeddings. Choose from `None`,\n",
      "        `\"timestep\"`, `\"identity\"`, `\"projection\"`, or `\"simple_projection\"`.\n",
      "    addition_embed_type (`str`, *optional*, defaults to `None`):\n",
      "        Configures an optional embedding which will be summed with the time embeddings. Choose from `None` or\n",
      "        \"text\". \"text\" will use the `TextTimeEmbedding` layer.\n",
      "    addition_time_embed_dim: (`int`, *optional*, defaults to `None`):\n",
      "        Dimension for the timestep embeddings.\n",
      "    num_class_embeds (`int`, *optional*, defaults to `None`):\n",
      "        Input dimension of the learnable embedding matrix to be projected to `time_embed_dim`, when performing\n",
      "        class conditioning with `class_embed_type` equal to `None`.\n",
      "    time_embedding_type (`str`, *optional*, defaults to `positional`):\n",
      "        The type of position embedding to use for timesteps. Choose from `positional` or `fourier`.\n",
      "    time_embedding_dim (`int`, *optional*, defaults to `None`):\n",
      "        An optional override for the dimension of the projected time embedding.\n",
      "    time_embedding_act_fn (`str`, *optional*, defaults to `None`):\n",
      "        Optional activation function to use only once on the time embeddings before they are passed to the rest of\n",
      "        the UNet. Choose from `silu`, `mish`, `gelu`, and `swish`.\n",
      "    timestep_post_act (`str`, *optional*, defaults to `None`):\n",
      "        The second activation function to use in timestep embedding. Choose from `silu`, `mish` and `gelu`.\n",
      "    time_cond_proj_dim (`int`, *optional*, defaults to `None`):\n",
      "        The dimension of `cond_proj` layer in the timestep embedding.\n",
      "    conv_in_kernel (`int`, *optional*, default to `3`): The kernel size of `conv_in` layer.\n",
      "    conv_out_kernel (`int`, *optional*, default to `3`): The kernel size of `conv_out` layer.\n",
      "    projection_class_embeddings_input_dim (`int`, *optional*): The dimension of the `class_labels` input when\n",
      "        `class_embed_type=\"projection\"`. Required when `class_embed_type=\"projection\"`.\n",
      "    class_embeddings_concat (`bool`, *optional*, defaults to `False`): Whether to concatenate the time\n",
      "        embeddings with the class embeddings.\n",
      "    mid_block_only_cross_attention (`bool`, *optional*, defaults to `None`):\n",
      "        Whether to use cross attention with the mid block when using the `UNetMidBlock2DSimpleCrossAttn`. If\n",
      "        `only_cross_attention` is given as a single boolean and `mid_block_only_cross_attention` is `None`, the\n",
      "        `only_cross_attention` value is used as the value for `mid_block_only_cross_attention`. Default to `False`\n",
      "        otherwise.\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mFile:\u001b[0m           /mnt/sda/ab/envs/virtualenvs/llama-Obh5TkSV-py3.10/lib/python3.10/site-packages/diffusers/models/unets/unet_2d_condition.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-Obh5TkSV-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
